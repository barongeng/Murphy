需要优化的地方：
1.卷积运算可以转化为矩阵的乘法，像im2col的实现，如果不优化的话是四层循环，优化之后是矩阵的乘法是二层循环
2.如果内存大小允许，尽量使用栈内存


MATLAB conv2卷积的实现
http://blog.csdn.net/celerychen2009/article/details/38852105

为什么卷积没有matlab的快：
1.matlab使用并行化的技术
2.exp函数可能使用查表法譬如提前计算了1000*1000并产生了一定程度的精度丢失
3.matalab的矩阵乘法也优化了，可能用并行化技术加速
4.matlab使用了im2col展开，im2col函数有可能也使用并行化技术

改进的几个方面：（*:optional）
 1.为了跟caffe一致，BLOB改成4维度，channel作为rgb通道，作为第一层输入神经元的个数，即为num
*2.反向传播是先计算最后一层的delta和loss，每层的计算是从top到bottom，计算bottom的delta、diff_k、diff_b，而不是计算top
 3.在初始化网络的时候设置网络的phase，即TRAIN和TEST，因为BLOB的batches在这两个phase有可能是不一样的，内存申请好就固定下来了
 4.需要添加一个net的模块，将封装底层的layerMgr
 5.加入json格式的网络结构文件，类似caffe中的protxt文件
 6.加入caffe中不同类型的层的前向传播，并验证与caffe结果一致
*7.加入caffe中不同类型的层的反向传播，并验证与caffe结果一致
 8.加入log模块
 
解决顺序：
	4-->1-->2-->3-->6-->5
	暂时先不解析json格式
	
/////////////////////////////////////////////////////////////////////////////////////////////////////
后续的考虑：
	有必要将c语言改成c++语言，可以使用protobuf的c++版本，只做前向的代码，甚至caffe的源码可以直接拿来用

达到的目标的优先顺序：
	1.与caffe进行前向传播代码的对接
		解决办法：
			将语言改成c++，protobuf部分代码从caffe直接拿来使用
			net模块的代码就不一定要抄caffe的了
			可以抄写BLOB的代码，使得层的实现可以直接拿来用，层的实现也可以用自己
			后续的层的实现可以用opencl实现，opencl也可以用c++实现的
	
	
	
	
	
	
	
	
